# Application name
spring.application.name=Catalogue

# Default profile: dev (H2)
spring.profiles.default=${SPRING_PROFILES_ACTIVE}

# Datasource MySQL
spring.datasource.url=${SPRING_DATASOURCE_URL}
spring.datasource.username=${SPRING_DATASOURCE_USERNAME}
spring.datasource.password=${SPRING_DATASOURCE_PASSWORD}

# JPA/Hibernate para MySQL
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.defer-datasource-initialization=false

# Kafka configuration (comun)
spring.kafka.bootstrap-servers=${KAFKA_BOOTSTRAP}
# Deshabilitar KafkaAdmin auto de Spring por defecto para evitar reconexiones en background
spring.kafka.admin.enabled=false
spring.kafka.admin.fail-fast=false
spring.kafka.consumer.group-id=inventario-ms
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.listener.ack-mode=manual_immediate
spring.kafka.listener.concurrency=3
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
# Usar ErrorHandlingDeserializer para capturar SerializationException y evitar loops
spring.kafka.consumer.key-deserializer=org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
spring.kafka.consumer.properties.spring.deserializer.key.delegate.class=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.properties.spring.deserializer.value.delegate.class=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=*
# --- Force SASL on the AdminClient (used at startup) ---
spring.kafka.admin.properties.security.protocol=SASL_PLAINTEXT
spring.kafka.admin.properties.sasl.mechanism=SCRAM-SHA-512
spring.kafka.admin.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";

# --- Force SASL on the Producer ---
spring.kafka.producer.properties.security.protocol=SASL_PLAINTEXT
spring.kafka.producer.properties.sasl.mechanism=SCRAM-SHA-512
spring.kafka.producer.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";

# --- Force SASL on the Consumer ---
spring.kafka.consumer.properties.security.protocol=SASL_PLAINTEXT
spring.kafka.consumer.properties.sasl.mechanism=SCRAM-SHA-512
spring.kafka.consumer.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";
#----sebas fix----
spring.kafka.consumer.properties.spring.json.use.type.headers=false
spring.kafka.consumer.properties.spring.json.value.default.type=ar.edu.uade.catalogue.messaging.EventMessage
#-------sebas fix-------------
spring.kafka.properties.security.protocol=SASL_PLAINTEXT
spring.kafka.properties.sasl.mechanism=SCRAM-SHA-512
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USERNAME}" password="${KAFKA_PASSWORD}";



# Inventario Kafka
inventario.kafka.topic=ventas
inventario.kafka.sales-topic=ventas
inventario.kafka.concurrency=3
inventario.kafka.error.maxAttempts=3
inventario.kafka.error.backoff.ms=500
inventario.kafka.dlq.enabled=false
inventario.kafka.dlq.topicSuffix=.dlq
# Desactivar admin y creacion de topicos por defecto (se pueden habilitar por profile)
inventario.kafka.enabled=true
inventario.kafka.admin.enabled=false
inventario.kafka.create-topics=false
# Timeout del probe/AdminClient
inventario.kafka.connect.apiTimeout.ms=2000

# Server
server.port=${SERVER_PORT:5000}
server.servlet.context-path=/api
server.forward-headers-strategy=framework
# AWS S3
spring.cloud.aws.credentials.access-key=${AWS_ACCESS_KEY_ID}
spring.cloud.aws.credentials.secret-key=${AWS_SECRET_ACCESS_KEY}

# Communication (middleware)
communication.intermediary.url=${KAFKA_MIDDLEWARE_URL:http://localhost:8090}

# Keycloak (client_credentials)
keycloak.token.url=${KEYCLOAK_TOKEN_URL:http://localhost:8080/realms/ecommerce/protocol/openid-connect/token}
keycloak.client-id=storage-app
keycloak.client-secret=${KEYCLOAK_CLIENT_SECRET}
keycloak.refresh.enabled=false

# Feature flags
communication.enabled=true

# Listener tolerance
spring.kafka.listener.missing-topics-fatal=false
spring.kafka.properties.max.block.ms=5000
